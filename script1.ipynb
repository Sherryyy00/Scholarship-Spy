{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayUW4qXm9egx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import platform\n",
        "if platform.system() == \"Windows\":\n",
        "    try:\n",
        "        import requests\n",
        "        from parsel import Selector\n",
        "        from fake_headers import Headers\n",
        "    except ImportError:\n",
        "        os.system('python -m pip install requests')\n",
        "        os.system('python -m pip install parsel')\n",
        "        os.system('python -m pip install fake_headers')\n",
        "else:\n",
        "    try:\n",
        "        import requests\n",
        "        from parsel import Selector\n",
        "        from fake_headers import Headers\n",
        "    except ImportError:\n",
        "        os.system('python3 -m pip install requests')\n",
        "        os.system('python3 -m pip install parsel')\n",
        "        os.system('python3 -m pip install fake_headers')\n",
        "\n",
        "\n",
        "import requests\n",
        "from parsel import Selector\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from fake_headers import Headers\n",
        "\n",
        "def getdata(link):\n",
        "    if link not in alreadyscrapped:\n",
        "        req = requests.get(link,headers=Headers().generate())\n",
        "        time.sleep(random.randint(3,8))\n",
        "        response = Selector(text=req.text)\n",
        "\n",
        "        title = response.xpath('.//h1/text()').extract_first()\n",
        "        try:\n",
        "            image_link = response.xpath('.//*[@class=\"scholarship-card\"]/div/@style').extract_first().replace(\"background-image: url('\",\"\").replace(\"')\",\"\")\n",
        "        except:\n",
        "            image_link = ''\n",
        "        tution_structure = '\\n'.join(response.xpath('.//[@class=\"icon-dollor\"]/following-sibling::text() | .//[@class=\"icon-dollor\"]/following-sibling::span/text()').extract())\n",
        "        university_name = response.xpath('.//[@class=\"icon-place\"]/following-sibling::text() | .//[@class=\"icon-place\"]/following-sibling::span/text()').extract_first()\n",
        "        degree = response.xpath('.//*[@class=\"icon-Bachelor2\"]/following-sibling::text()').extract_first()\n",
        "        subject = response.xpath('.//[@class=\"icon-book\"]/following-sibling::text() | .//[@class=\"icon-book\"]/following-sibling::span/text()').extract_first()\n",
        "        eligiblity = '\\n'.join(response.xpath('.//[@class=\"icon-world\"]/following-sibling::text() | .//[@class=\"icon-world\"]/following-sibling::span/text()').extract())\n",
        "        country = response.xpath('.//*[@class=\"icon-map\"]/following-sibling::text()').extract_first()\n",
        "        apply_date = response.xpath('.//*[@class=\"icon-calendar\"]/following-sibling::text()').extract_first()\n",
        "        try:\n",
        "            scholarship_details = '\\n'.join([i.strip() for i in response.xpath('.//*[@class=\"scholarship-details\"]//text()').extract() if '{' not in i and 'View' not in i and i.strip() and 'Share' not in i])\n",
        "        except:\n",
        "            scholarship_details = ''\n",
        "\n",
        "\n",
        "        with open(\"scholarshipads.csv\",\"a\",newline=\"\",encoding=\"utf-8\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([link,title,image_link,tution_structure,university_name,degree,subject,eligiblity,country,apply_date,scholarship_details])\n",
        "            print([link,title,image_link,tution_structure,university_name,degree,subject,eligiblity,country,apply_date,scholarship_details])\n",
        "\n",
        "    else:\n",
        "        print(\"Exists ...\")\n",
        "\n",
        "def scrape_country(link):\n",
        "    req = requests.get(link,headers=Headers().generate())\n",
        "    time.sleep(random.randint(3,8))\n",
        "    response = Selector(text=req.text)\n",
        "    links = response.xpath('.//h2/a/@href[contains(.,\"http\")]').extract()\n",
        "    for link in links:\n",
        "        print(\"link: \"+str(link))\n",
        "        getdata(link)\n",
        "\n",
        "\n",
        "    nextlink = response.xpath('.//*[@class=\"next \"]/@href').extract_first()\n",
        "    if nextlink:\n",
        "        print(\"Nextlink :\"+str(nextlink))\n",
        "        scrape_country(nextlink)\n",
        "\n",
        "\n",
        "#if _name_ == '_main_':\n",
        "\n",
        "    if \"scholarshipads.csv\" not in os.listdir(os.getcwd()):\n",
        "        with open(\"scholarshipads.csv\",\"a\",newline=\"\",encoding=\"utf-8\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(['link','title','image_link','tution_structure','university_name','degree','subject','eligiblity','country','apply_date','scholarship details'])\n",
        "\n",
        "    alreadyscrapped = []\n",
        "    with open(\"scholarshipads.csv\",\"r\") as r:\n",
        "        reader = csv.reader(r)\n",
        "        for line in reader:\n",
        "            alreadyscrapped.append(line[0])\n",
        "\n",
        "\n",
        "    print(alreadyscrapped)\n",
        "    url = \"https://www.scholarshipsads.com/awarding-countries/\"\n",
        "    req = requests.get(url,headers=Headers().generate())\n",
        "    time.sleep(random.randint(3,8))\n",
        "\n",
        "    response = Selector(text=req.text)\n",
        "    country_links = list(set(response.xpath('.//*[@class=\"card-body\"]/ul/li/a/@href').extract()))\n",
        "\n",
        "    for country_link in country_links:\n",
        "        scrape_country(country_link)"
      ]
    }
  ]
}